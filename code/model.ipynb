{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WZsJE6InQvH"
      },
      "source": [
        "# Problem 3 Sample Code\n",
        "\n",
        "This sample code is meant as a guide on how to use PyTorch and how to use the relevant model layers. This not a guide on how to design a network and the network in this example is intentionally designed to have poor performace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pRd994oKnQvI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T8ui5hmKnQvJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lucas A\\AppData\\Local\\Temp\\ipykernel_2212\\3329026516.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train.drop(['split'], axis=1, inplace=True)\n",
            "C:\\Users\\Lucas A\\AppData\\Local\\Temp\\ipykernel_2212\\3329026516.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test.drop(['split'], axis=1, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('out.csv')\n",
        "df.drop(['uid'], axis=1, inplace=True)\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "msk = np.random.rand(len(df)) <= 0.7\n",
        "\n",
        "train = df[msk]\n",
        "train.drop(['split'], axis=1, inplace=True)\n",
        "test = df[~msk]\n",
        "test.drop(['split'], axis=1, inplace=True)\n",
        "\n",
        "x_train = np.array(train[['chi','lin_reg','lin_reg_chi','stddev_step_speed']])\n",
        "y_train = np.array(train['label'])\n",
        "\n",
        "x_test = np.array(train[['chi','lin_reg','lin_reg_chi','stddev_step_speed']])\n",
        "y_test = np.array(train['label'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2CNJNoQnQvK",
        "outputId": "807f4849-3783-4e7b-c240-82ffbe229aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 <class 'torch.Tensor'> <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset), type(train_dataset[0][0]), type(train_dataset[0][1]))\n",
        "\n",
        "# tensor, target = train_dataset[0]\n",
        "# print(\"num train images: \"+str(len(train_dataset)))\n",
        "# print(\"num test images: \"+str(len(test_dataset)))\n",
        "# print(\"height: \"+str(len(tensor[0])))\n",
        "# print(\"width: \"+str(len(tensor[0][0])))\n",
        "# print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kAG49-4nQvK"
      },
      "source": [
        "We can convert images to numpy arrays and plot them with matplotlib:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0VSOS2TnQvL"
      },
      "source": [
        "## Network Definition\n",
        "Let's instantiate a model and take a look at the layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT73uPcbnQvL",
        "outputId": "9af8e298-58c2-4110-c1c4-f7abd30472c9",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=784, out_features=400, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=400, out_features=300, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=300, out_features=280, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=280, out_features=20, bias=True)\n",
            "  (8): ReLU()\n",
            "  (9): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (10): Dropout(p=0.07, inplace=False)\n",
            "  (11): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = nn.Sequential(\n",
        "    # In problem 2, we don't use the 2D structure of an image at all. Our network\n",
        "    # takes in a flat vector of the pixel values as input.\n",
        "\n",
        "    # nn.Linear(784, 400),\n",
        "    # nn.ReLU(),\n",
        "    # nn.Linear(400, 300),\n",
        "    # nn.ReLU(),\n",
        "    # nn.Linear(300, 280),\n",
        "    # nn.ReLU(),\n",
        "    # nn.Linear(280, 20),\n",
        "    # nn.ReLU(),\n",
        "    # nn.Linear(20, 10),\n",
        "    # nn.Dropout(0.07),\n",
        "    # nn.Softmax(dim=1)\n",
        ")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkzr6hvjnQvM"
      },
      "source": [
        "## Training\n",
        "We also choose an optimizer and a loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PofNcGjonQvM"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLaXzBQjnQvM"
      },
      "source": [
        "We could write our training procedure manually and directly index the `Dataset` objects, but the `DataLoader` object conveniently creates an iterable for automatically creating random minibatches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbACTaKMnQvM",
        "outputId": "efcdb3a9-5f9b-44cd-ab94-2cdc2698c12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2141766464899450509\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=80, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=80, shuffle=True) \n",
        "\n",
        "torch.manual_seed(15552494823729223621)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EJRa6ndnQvM"
      },
      "source": [
        "We now write our backpropagation loop, training for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3-pMlInQvM",
        "outputId": "26e030ff-ea74-4177-e94e-7437abee7432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1  Loss: 1.6938\n",
            "Train Epoch: 2  Loss: 1.6158\n",
            "Train Epoch: 3  Loss: 1.6253\n",
            "Train Epoch: 4  Loss: 1.6082\n",
            "Train Epoch: 5  Loss: 1.6175\n",
            "Train Epoch: 6  Loss: 1.5629\n",
            "Train Epoch: 7  Loss: 1.5517\n",
            "Train Epoch: 8  Loss: 1.5373\n",
            "Train Epoch: 9  Loss: 1.6572\n",
            "Train Epoch: 10  Loss: 1.5556\n",
            "Train Epoch: 11  Loss: 1.5591\n",
            "Train Epoch: 12  Loss: 1.5440\n",
            "Train Epoch: 13  Loss: 1.5423\n",
            "Train Epoch: 14  Loss: 1.5126\n",
            "Train Epoch: 15  Loss: 1.4914\n",
            "Train Epoch: 16  Loss: 1.5057\n",
            "Train Epoch: 17  Loss: 1.5051\n",
            "Train Epoch: 18  Loss: 1.5429\n",
            "Train Epoch: 19  Loss: 1.5088\n",
            "Train Epoch: 20  Loss: 1.5306\n"
          ]
        }
      ],
      "source": [
        "# Some layers, such as Dropout, behave differently during training\n",
        "model.train()\n",
        "\n",
        "for epoch in range(20):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Erase accumulated gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Weight update\n",
        "        optimizer.step()\n",
        "\n",
        "    # Track loss each epoch\n",
        "    print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4p-4iZDnQvN"
      },
      "source": [
        "## Testing\n",
        "We can perform forward passes through the network without saving gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGzLHGFfnQvN",
        "outputId": "70c957a0-e909-4b4b-c0e0-02d70f65b51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0186, Accuracy: 9715/10000 (97.1500)\n"
          ]
        }
      ],
      "source": [
        "# Putting layers like Dropout into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "# Turning off automatic differentiation\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "      (test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
